// import a couple things
import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}
import org.apache.spark.ml.util.Identifiable
import org.apache.spark.sql.functions._
import org.educationaldatamining.spark.bkt.{BKTEvaluator, BKTModel, GivenParameterBKTEstimator}

// Let's set up a BKT model with some reasonable parameters
val bkt = new BKTModel( Identifiable.randomUID("Find Y BKT") ).setStudentResultsCol("Results").setPInit( 0.3 ).setPLearn( 0.2 ).setPGuess( 0.15 ).setPSlip( 0.2 )

// run BKT on the data
val predicted = bkt.transform( studentResults )

// have a look at the predictions:
predicted.show

// evaluate the model
val bktEval = new BKTEvaluator().setStudentResultsCol("Results")
println( bktEval.getMetricName +" for the BKT model is: "+ bktEval.evaluate(predicted) )

// let's do a brute-force grid-search
val pGrid = new ParamGridBuilder().addGrid( bkt.pInit, 0.1 until 1.0 by 0.1 ).addGrid( bkt.pLearn, 0.1 until 1.0 by 0.1 ).addGrid( bkt.pGuess, 0.1 until 0.5 by 0.1 ).addGrid( bkt.pSlip, 0.1 until 0.5 by 0.1 )

// and some cross-validation
val cv = new CrossValidator().setEstimator(new GivenParameterBKTEstimator()).setEvaluator(bktEval).setEstimatorParamMaps(pGrid.build()).setNumFolds(4)

// fitting the cross-validator will now run a grid-search over BKT parameters
val bfModel = cv.fit( train )

// let's see how we did on our test set
println( bktEval.getMetricName +" of our test set was: "+ bktEval.evaluate(bfModel.transform( test )) )